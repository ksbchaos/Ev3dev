{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#np.random.seed(0)\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Input datasets\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "epochs = 100000\n",
    "lr = 0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "\n",
    "print(\"Initial hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "\t#Forward Propagation\n",
    "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "\thidden_layer_activation += hidden_bias\n",
    "\thidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "\toutput_layer_activation += output_bias\n",
    "\tpredicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "\t#Backpropagation\n",
    "\terror = expected_output - predicted_output\n",
    "\td_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\t\n",
    "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "\td_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "\t#Updating Weights and Biases\n",
    "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression 사용한 XOR 문제 해결\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "x_data = [[0, 0],\n",
    "\n",
    "          [0, 1],\n",
    "\n",
    "          [1, 0],\n",
    "\n",
    "          [1, 1]]\n",
    "\n",
    "y_data = [[0],\n",
    "\n",
    "          [1],\n",
    "\n",
    "          [1],\n",
    "\n",
    "          [0]]\n",
    "\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "\n",
    "                  X: x_data, Y: y_data}), sess.run(W))\n",
    "\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8495944 [[1.6405023]\n",
      " [0.3942649]]\n",
      "100 0.6946042 [[1.1914935 ]\n",
      " [0.25289184]]\n",
      "200 0.6941409 [[1.1603446 ]\n",
      " [0.26799375]]\n",
      "300 0.69379896 [[1.1403233]\n",
      " [0.2872346]]\n",
      "400 0.69348955 [[1.1225953 ]\n",
      " [0.30747828]]\n",
      "500 0.69320047 [[1.1066839 ]\n",
      " [0.32887262]]\n",
      "600 0.69292206 [[1.092335  ]\n",
      " [0.35163155]]\n",
      "700 0.6926452 [[1.0793256]\n",
      " [0.3759712]]\n",
      "800 0.69236135 [[1.0674614 ]\n",
      " [0.40211752]]\n",
      "900 0.6920615 [[1.0565662 ]\n",
      " [0.43031457]]\n",
      "1000 0.6917352 [[1.0464873]\n",
      " [0.4608322]]\n",
      "1100 0.6913707 [[1.0370904 ]\n",
      " [0.49397543]]\n",
      "1200 0.69095343 [[1.0282602 ]\n",
      " [0.53009355]]\n",
      "1300 0.69046545 [[1.0199002]\n",
      " [0.5695919]]\n",
      "1400 0.68988377 [[1.0119317]\n",
      " [0.6129453]]\n",
      "1500 0.6891787 [[1.0042961 ]\n",
      " [0.66071254]]\n",
      "1600 0.6883111 [[0.996955  ]\n",
      " [0.71355784]]\n",
      "1700 0.6872297 [[0.98989457]\n",
      " [0.7722688 ]]\n",
      "1800 0.68586594 [[0.98312914]\n",
      " [0.83777905]]\n",
      "1900 0.6841297 [[0.97670627]\n",
      " [0.9111839 ]]\n",
      "2000 0.6819037 [[0.97071654]\n",
      " [0.99374545]]\n",
      "2100 0.67903864 [[0.9653066]\n",
      " [1.0868697]]\n",
      "2200 0.6753526 [[0.9607008]\n",
      " [1.1920408]]\n",
      "2300 0.67063737 [[0.9572354]\n",
      " [1.3106855]]\n",
      "2400 0.66467774 [[0.95541584]\n",
      " [1.4439584 ]]\n",
      "2500 0.6572865 [[0.95599395]\n",
      " [1.5924609 ]]\n",
      "2600 0.6483522 [[0.9600658]\n",
      " [1.7559448]]\n",
      "2700 0.6378836 [[0.9691599]\n",
      " [1.9331142]]\n",
      "2800 0.6260291 [[0.98528236]\n",
      " [2.1216297 ]]\n",
      "2900 0.6130464 [[1.010892 ]\n",
      " [2.3184009]]\n",
      "3000 0.5992252 [[1.0488183]\n",
      " [2.5200856]]\n",
      "3100 0.58478254 [[1.1021732]\n",
      " [2.7236717]]\n",
      "3200 0.56976414 [[1.174326 ]\n",
      " [2.9269507]]\n",
      "3300 0.55396825 [[1.2689859]\n",
      " [3.128758 ]]\n",
      "3400 0.5368845 [[1.3903922]\n",
      " [3.32898  ]]\n",
      "3500 0.51763976 [[1.5435677]\n",
      " [3.5283213]]\n",
      "3600 0.49497908 [[1.7344105]\n",
      " [3.727866 ]]\n",
      "3700 0.46741876 [[1.9690534]\n",
      " [3.9284847]]\n",
      "3800 0.43382 [[2.2515166]\n",
      " [4.13027  ]]\n",
      "3900 0.39439958 [[2.579558 ]\n",
      " [4.3323936]]\n",
      "4000 0.35138693 [[2.9416556]\n",
      " [4.5334806]]\n",
      "4100 0.30831578 [[3.3192952]\n",
      " [4.7320876]]\n",
      "4200 0.2683899 [[3.6935863]\n",
      " [4.926825 ]]\n",
      "4300 0.23341101 [[4.0506983]\n",
      " [5.116364 ]]\n",
      "4400 0.20380226 [[4.3831935]\n",
      " [5.299553 ]]\n",
      "4500 0.17915796 [[4.6886277]\n",
      " [5.475547 ]]\n",
      "4600 0.15874925 [[4.967544]\n",
      " [5.643855]]\n",
      "4700 0.14181387 [[5.221937 ]\n",
      " [5.8043146]]\n",
      "4800 0.1276775 [[5.454323 ]\n",
      " [5.9570093]]\n",
      "4900 0.115785375 [[5.6672463]\n",
      " [6.102192 ]]\n",
      "5000 0.10569602 [[5.863071]\n",
      " [6.240214]]\n",
      "5100 0.09706278 [[6.0438924]\n",
      " [6.3714814]]\n",
      "5200 0.08961463 [[6.211525 ]\n",
      " [6.4964194]]\n",
      "5300 0.08313867 [[6.3675385]\n",
      " [6.6154523]]\n",
      "5400 0.077467024 [[6.513272 ]\n",
      " [6.7289896]]\n",
      "5500 0.07246647 [[6.6498756]\n",
      " [6.8374133]]\n",
      "5600 0.06803003 [[6.778332 ]\n",
      " [6.9410915]]\n",
      "5700 0.06407161 [[6.899487 ]\n",
      " [7.0403585]]\n",
      "5800 0.06052111 [[7.014068]\n",
      " [7.135523]]\n",
      "5900 0.057320982 [[7.12271  ]\n",
      " [7.2268677]]\n",
      "6000 0.05442372 [[7.2259626]\n",
      " [7.3146515]]\n",
      "6100 0.051789746 [[7.3243084]\n",
      " [7.3991127]]\n",
      "6200 0.049385954 [[7.4181705]\n",
      " [7.4804716]]\n",
      "6300 0.047184348 [[7.5079207]\n",
      " [7.5589275]]\n",
      "6400 0.045161307 [[7.5938883]\n",
      " [7.634661 ]]\n",
      "6500 0.043296486 [[7.676368]\n",
      " [7.707841]]\n",
      "6600 0.04157266 [[7.7556214]\n",
      " [7.7786207]]\n",
      "6700 0.03997478 [[7.8318815]\n",
      " [7.847144 ]]\n",
      "6800 0.0384899 [[7.9053593]\n",
      " [7.9135394]]\n",
      "6900 0.037106846 [[7.976244 ]\n",
      " [7.9779263]]\n",
      "7000 0.035815664 [[8.044706]\n",
      " [8.040417]]\n",
      "7100 0.034607746 [[8.110904]\n",
      " [8.101111]]\n",
      "7200 0.033475474 [[8.174975]\n",
      " [8.160105]]\n",
      "7300 0.032412097 [[8.237054]\n",
      " [8.217488]]\n",
      "7400 0.03141174 [[8.297251]\n",
      " [8.273338]]\n",
      "7500 0.030468997 [[8.355676]\n",
      " [8.327735]]\n",
      "7600 0.029579187 [[8.412429]\n",
      " [8.380744]]\n",
      "7700 0.028738055 [[8.467602]\n",
      " [8.432437]]\n",
      "7800 0.027941797 [[8.5212755]\n",
      " [8.482872 ]]\n",
      "7900 0.027187023 [[8.573533]\n",
      " [8.532104]]\n",
      "8000 0.02647056 [[8.62444 ]\n",
      " [8.580189]]\n",
      "8100 0.025789667 [[8.674065]\n",
      " [8.627179]]\n",
      "8200 0.025141805 [[8.72247 ]\n",
      " [8.673119]]\n",
      "8300 0.024524696 [[8.769713]\n",
      " [8.718052]]\n",
      "8400 0.023936218 [[8.815848]\n",
      " [8.76202 ]]\n",
      "8500 0.023374429 [[8.860925]\n",
      " [8.805065]]\n",
      "8600 0.022837684 [[8.904987]\n",
      " [8.847222]]\n",
      "8700 0.02232426 [[8.948084]\n",
      " [8.888524]]\n",
      "8800 0.021832757 [[8.9902525]\n",
      " [8.929006 ]]\n",
      "8900 0.021361826 [[9.031533 ]\n",
      " [8.9686985]]\n",
      "9000 0.02091019 [[9.071961]\n",
      " [9.00763 ]]\n",
      "9100 0.020476716 [[9.11157]\n",
      " [9.04583]]\n",
      "9200 0.020060388 [[9.1503935]\n",
      " [9.083324 ]]\n",
      "9300 0.019660167 [[9.188459]\n",
      " [9.120137]]\n",
      "9400 0.019275213 [[9.225799]\n",
      " [9.156291]]\n",
      "9500 0.018904641 [[9.262437]\n",
      " [9.191811]]\n",
      "9600 0.018547649 [[9.298398]\n",
      " [9.226716]]\n",
      "9700 0.018203594 [[9.333709]\n",
      " [9.261028]]\n",
      "9800 0.017871726 [[9.368395]\n",
      " [9.294765]]\n",
      "9900 0.017551418 [[9.40247 ]\n",
      " [9.327949]]\n",
      "10000 0.017242104 [[9.435962]\n",
      " [9.360593]]\n",
      "\n",
      "Hypothesis: \n",
      " [[0.98507744]\n",
      " [0.02008664]\n",
      " [0.98400396]\n",
      " [0.01736438]] \n",
      "Correct: \n",
      " [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "x_data = [[0, 1], [0, 0], [1, 0], [1, 1]]\n",
    "\n",
    "y_data = [[1], [0], [1], [0]]\n",
    "\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W2))\n",
    "\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print(\"\\nHypothesis: \\n\", h, \"\\nCorrect: \\n\", c, \"\\nAccuracy: \\n\", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
