{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [학습에 필요한 모듈 선언]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples.tutorials'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6106c28bd90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples.tutorials'"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [환경설정]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "learningRate = 0.001\n",
    "\n",
    "# 총 학습 횟수\n",
    "totalEpochs = 20\n",
    "# 학습데이터를 나누기 위한 값\n",
    "# 학습데이터 총수 / batch_size = 한번의 epoch 쓰이는 데이터 수\n",
    "batch_size = 200\n",
    "\n",
    "# W, b 변수 생성 타입 (1 : random_normal, 2: truncated_normal, 3:  random_uniform)\n",
    "randomVariableType = 1\n",
    "\n",
    "# input Layer 크기\n",
    "# 입력 데이터 크기 784 (손글씨 이미지는 28 * 28 픽셀로 총 784개)\n",
    "inputDataSize = 28 * 28 # 입력 데이터 고정값(수정불가)\n",
    "\n",
    "# hidden Layer 크기\n",
    "hiddenLayer1Size = 1024\n",
    "hiddenLayer2Size = 512\n",
    "hiddenLayer3Size = 256\n",
    "\n",
    "# output Layer 크기\n",
    "# 출력값 크기 (Output Layer에서 출력되 데이터(0~9까지 숫자)\n",
    "outputLayerSize = 128\n",
    "outputDataSize = 10 # 출력값 크기 고정(수정불가)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [빌드단계] Step 1) 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공식 tensorflow github에서 제공하는 mnist dataset 다운로드\n",
    "# 결과 데이터는 ont hot encoding을 적용\n",
    "mnist = input_data.read_data_sets(\"./dataset\", one_hot = True)\n",
    "\n",
    "print(\"Train data num        : {}\".format(mnist.train.num_examples))\n",
    "print(\"Train data shape      : {}\".format(mnist.train.images.shape))\n",
    "print(\"Test data num         : {}\".format(mnist.test.num_examples ))\n",
    "print(\"Train data shape      : {}\".format(mnist.test.images.shape))\n",
    "print(\"Validation data num   : {}\".format(mnist.validation.num_examples))\n",
    "print(\"Validation data shape : {}\".format(mnist.validation.images.shape))\n",
    "\n",
    "# 손글씨 이미지 픽셀로 표현 방법\n",
    "image = [[1,2,3,4,5],\n",
    "         [5,4,3,2,1]]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "# 손글씨 이미지 그래프로 출력\n",
    "batch = mnist.train.next_batch(1)\n",
    "plotData = batch[0]\n",
    "plotData = plotData.reshape(28, 28)\n",
    "plt.imshow(plotData, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [빌드단계] Step 2) 모델 생성을 위한 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터가 들어갈 플레이스 홀더 선언\n",
    "X = tf.placeholder(tf.float32, [None, inputDataSize])\n",
    "# 학습데이터가 들어갈 플레이스 홀더 선언\n",
    "Y = tf.placeholder(tf.float32, [None, outputDataSize])\n",
    "\n",
    "# 임의의 난수를 선언하여 W,b 변수의 초기값을 선언 및 Neural Network Layer 구성\n",
    "if randomVariableType == 1:\n",
    "    # 1 : random_normal\n",
    "    # Input Layer\n",
    "    W_input = tf.Variable(tf.random_normal([inputDataSize, hiddenLayer1Size]),\n",
    "                          name = 'Weight_input')\n",
    "    b_input = tf.Variable(tf.random_normal([hiddenLayer1Size]), name = 'bias_input')\n",
    "\n",
    "    # Hidden Layer\n",
    "    # Layer1\n",
    "    W_hidden1 = tf.Variable(tf.random_normal([hiddenLayer1Size, hiddenLayer2Size]),\n",
    "                            name = 'Weight_hidden1')\n",
    "    b_hidden1 = tf.Variable(tf.random_normal([hiddenLayer2Size]),\n",
    "                            name = 'bias_hidden1')\n",
    "\n",
    "    # Layer2\n",
    "    W_hidden2 = tf.Variable(tf.random_normal([hiddenLayer2Size, hiddenLayer3Size]),\n",
    "                            name = 'Weight_hidden2')\n",
    "    b_hidden2 = tf.Variable(tf.random_normal([hiddenLayer3Size]),\n",
    "                            name = 'bias_hidden2')\n",
    "\n",
    "    # Layer3\n",
    "    W_hidden3 = tf.Variable(tf.random_normal([hiddenLayer3Size, outputLayerSize]),\n",
    "                            name = 'Weight_hidden3')\n",
    "    b_hidden3 = tf.Variable(tf.random_normal([outputLayerSize]),\n",
    "                            name = 'bias_hidden3')\n",
    "\n",
    "    # Output Layer\n",
    "    W_output = tf.Variable(tf.random_normal([outputLayerSize,outputDataSize]),\n",
    "                           name = 'Weight_output')\n",
    "    b_output = tf.Variable(tf.random_normal([outputDataSize]),\n",
    "                           name = 'bias_output')\n",
    "\n",
    "elif randomVariableType == 2:\n",
    "    # 2 : truncated_normal\n",
    "\n",
    "    # Input Layer\n",
    "    W_input = tf.Variable(tf.truncated_normal([inputDataSize, hiddenLayer1Size]),\n",
    "                          name = 'Weight_input')\n",
    "    b_input = tf.Variable(tf.truncated_normal([hiddenLayer1Size]),\n",
    "                          name = 'bias_input')\n",
    "\n",
    "    # Hidden Layer\n",
    "    # Layer1\n",
    "    W_hidden1 = tf.Variable(tf.truncated_normal([hiddenLayer1Size, hiddenLayer2Size]),\n",
    "                            name = 'Weight_hidden1')\n",
    "    b_hidden1 = tf.Variable(tf.truncated_normal([hiddenLayer2Size]), name = 'bias_hidden1')\n",
    "\n",
    "    # Layer2\n",
    "    W_hidden2 = tf.Variable(tf.truncated_normal([hiddenLayer2Size, hiddenLayer3Size]),\n",
    "                            name = 'Weight_hidden2')\n",
    "    b_hidden2 = tf.Variable(tf.truncated_normal([hiddenLayer3Size]),\n",
    "                            name = 'bias_hidden2')\n",
    "\n",
    "    # Layer3\n",
    "    W_hidden3 = tf.Variable(tf.truncated_normal([hiddenLayer3Size, outputLayerSize]),\n",
    "                            name = 'Weight_hidden3')\n",
    "    b_hidden3 = tf.Variable(tf.truncated_normal([outputLayerSize]),\n",
    "                            name = 'bias_hidden3')\n",
    "\n",
    "    # Output Layer\n",
    "    W_output = tf.Variable(tf.truncated_normal([outputLayerSize, outputDataSize]),\n",
    "                           name = 'Weight_output')\n",
    "    b_output = tf.Variable(tf.truncated_normal([outputDataSize]),\n",
    "                           name = 'bias_output')\n",
    "\n",
    "elif randomVariableType == 3:\n",
    "    # 3 : random_uniform\n",
    "    # Input Layer\n",
    "    W_input = tf.Variable(tf.random_uniform([inputDataSize, hiddenLayer1Size]),\n",
    "                          name = 'Weight_input')\n",
    "    b_input = tf.Variable(tf.random_uniform([hiddenLayer1Size]),\n",
    "                          name = 'bias_input')\n",
    "\n",
    "    # Hidden Layer\n",
    "    # Layer1\n",
    "    W_hidden1 = tf.Variable(tf.random_uniform([hiddenLayer1Size, hiddenLayer2Size]),\n",
    "                            name = 'Weight_hidden1')\n",
    "    b_hidden1 = tf.Variable(tf.random_uniform([hiddenLayer2Size]),\n",
    "                            name = 'bias_hidden1')\n",
    "\n",
    "    # Layer2\n",
    "    W_hidden2 = tf.Variable(tf.random_uniform([hiddenLayer2Size, hiddenLayer3Size]),\n",
    "                            name = 'Weight_hidden2')\n",
    "    b_hidden2 = tf.Variable(tf.random_uniform([hiddenLayer3Size]),\n",
    "                            name = 'bias_hidden2')\n",
    "\n",
    "    # Layer3\n",
    "    W_hidden3 = tf.Variable(tf.random_uniform([hiddenLayer3Size, outputLayerSize]),\n",
    "                            name = 'Weight_hidden3')\n",
    "    b_hidden3 = tf.Variable(tf.random_uniform([outputLayerSize]),\n",
    "                            name = 'bias_hidden3')\n",
    "\n",
    "    # Output Layer\n",
    "    W_output = tf.Variable(tf.random_uniform([outputLayerSize, outputDataSize]),\n",
    "                           name = 'Weight_output')\n",
    "    b_output = tf.Variable(tf.random_uniform([outputDataSize]),\n",
    "                           name = 'bias_output')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [빌드단계] 3) 학습 모델 그래프 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-1) 학습데이터를 대표 하는 가설 그래프 선언\n",
    "# hypothesis - Input Layer\n",
    "Layer_input_hypothesis = tf.nn.relu(tf.matmul(X, W_input)+b_input)\n",
    "# hypothesis - Hidden Layer\n",
    "Layer_hidden1_hypothesis = tf.nn.relu(tf.matmul(Layer_input_hypothesis,W_hidden1)+b_hidden1)\n",
    "Layer_hidden2_hypothesis = tf.nn.relu(tf.matmul(Layer_hidden1_hypothesis,W_hidden2)+b_hidden2)\n",
    "Layer_hidden3_hypothesis = tf.nn.relu(tf.matmul(Layer_hidden2_hypothesis,W_hidden3)+b_hidden3)\n",
    "# hypothesis - Output Layer\n",
    "Layer_output_hypothesis_logit = tf.matmul(Layer_hidden3_hypothesis, W_output)+b_output\n",
    "\n",
    "# 3-2) 비용함수(오차함수,손실함수) 선언\n",
    "costFunction = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Layer_output_hypothesis_logit, labels=Y))\n",
    "\n",
    "# 3-3) 비용함수의 값이 최소가 되도록 하는 최적화함수 선언\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learningRate)\n",
    "train = optimizer.minimize(costFunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실행단계] 학습 모델 그래프를 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행을 위한 세션 선언\n",
    "sess = tf.Session()\n",
    "# 최적화 과정을 통하여 구해질 변수 W,b 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 예측값, 정확도 수식 선언\n",
    "predicted = tf.equal(tf.argmax(Layer_output_hypothesis_logit, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted, tf.float32))\n",
    "\n",
    "# 학습 정확도를 저장할 리스트 선언\n",
    "train_accuracy = list()\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(\"Train(Optimization) Start \")\n",
    "\n",
    "for epoch in range(totalEpochs):\n",
    "    average_costFunction = 0\n",
    "    # 전체 batch 사이즈 구하기 (55000 / 200 = 275)\n",
    "    totalBatch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for step in range(totalBatch):\n",
    "        batchX, batchY = mnist.train.next_batch(batch_size)\n",
    "        cost_val, acc_val, _ = sess.run([costFunction, accuracy, train],\n",
    "                                feed_dict = {X : batchX, Y:batchY})\n",
    "        train_accuracy.append(acc_val)\n",
    "        average_costFunction = cost_val / totalBatch\n",
    "\n",
    "    print(\"epoch : {}, cost = {}\".format(epoch,average_costFunction))\n",
    "\n",
    "\n",
    "# 정확도 결과 확인 그래프\n",
    "plt.plot(range(len(train_accuracy)), train_accuracy, linewidth = 2, label = 'Training')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Result\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Train Finished\")\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(\"[Test Result]\")\n",
    "# 최적화가 끝난 학습 모델 테스트\n",
    "h_val, p_val, a_val = sess.run([Layer_output_hypothesis_logit, predicted, accuracy],\n",
    "                        feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n",
    "print(\"\\nHypothesis : {} \\nPrediction : {} \\nAccuracy : {}\".format(h_val,p_val,a_val))\n",
    "\n",
    "\n",
    "# matplotlib 를 이용하여 학습 결과를 시각화\n",
    "# 라벨 0 / 4 는 앞자리는 예측값 / 실제값 을 나타냄\n",
    "fig = plt.figure(figsize=(8,15))\n",
    "for i in range(10):\n",
    "    c = 1\n",
    "    for (image, label, h) in zip(mnist.test.images, mnist.test.labels, h_val):\n",
    "        prediction, actual = np.argmax(h), np.argmax(label)\n",
    "        if prediction != i:\n",
    "            continue\n",
    "        if (c < 4 and i == actual) or (c >= 4 and i != actual):\n",
    "            subplot = fig.add_subplot(10,6,i*6+c)\n",
    "            subplot.set_xticks([])\n",
    "            subplot.set_yticks([])\n",
    "            subplot.set_title('%d / %d' % (prediction, actual))\n",
    "            subplot.imshow(image.reshape((28,28)), vmin=0, vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "            c += 1\n",
    "            if c > 6:\n",
    "                break\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "#세션종료\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
