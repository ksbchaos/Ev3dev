{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [학습에 필요한 모듈 선언]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import datasets\n",
    "mnist=datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [환경설정]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "learningRate = 0.001\n",
    "\n",
    "# 총 학습 횟수\n",
    "totalEpochs = 20\n",
    "# 학습데이터를 나누기 위한 값\n",
    "# 학습데이터 총수 / batch_size = 한번의 epoch 쓰이는 데이터 수\n",
    "batch_size = 200\n",
    "\n",
    "# W, b 변수 생성 타입 (1 : random_normal, 2: truncated_normal, 3:  random_uniform)\n",
    "randomVariableType = 1\n",
    "\n",
    "# input Layer 크기\n",
    "# 입력 데이터 크기 784 (손글씨 이미지는 28 * 28 픽셀로 총 784개)\n",
    "inputDataSize = 28 * 28 # 입력 데이터 고정값(수정불가)\n",
    "\n",
    "# hidden Layer 크기\n",
    "hiddenLayer1Size = 1024\n",
    "hiddenLayer2Size = 512\n",
    "hiddenLayer3Size = 256\n",
    "\n",
    "# output Layer 크기\n",
    "# 출력값 크기 (Output Layer에서 출력되 데이터(0~9까지 숫자)\n",
    "outputLayerSize = 128\n",
    "outputDataSize = 10 # 출력값 크기 고정(수정불가)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [빌드단계] Step 1) 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape      : (60000, 28, 28)\n",
      "Train data shape      : (10000, 28, 28)\n",
      "Validation data shape : (60000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47040000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 공식 tensorflow github에서 제공하는 mnist dataset 다운로드\n",
    "# 결과 데이터는 ont hot encoding을 적용\n",
    "#mnist = input_data.read_data_sets(\"./dataset\", one_hot = True)\n",
    "#mnist = np.float16(input_data[0])\n",
    "(train,validation),(test,test1)=mnist.load_data()\n",
    "#print(\"Train data num        : {}\".format(mnist.train.num_examples))\n",
    "print(\"Train data shape      : {}\".format(train.shape))\n",
    "#print(\"Test data num         : {}\".format(mnist.test.num_examples ))\n",
    "print(\"Train data shape      : {}\".format(test.shape))\n",
    "#print(\"Validation data num   : {}\".format(mnist.validation.num_examples))\n",
    "print(\"Validation data shape : {}\".format(validation.shape))\n",
    "\n",
    "# 손글씨 이미지 픽셀로 표현 방법\n",
    "image = [[1,2,3,4,5],\n",
    "         [5,4,3,2,1]]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "# 손글씨 이미지 그래프로 출력\n",
    "#batch = mnist.train.next_batch(1)\n",
    "batch=train[1]\n",
    "print(train.size)\n",
    "\n",
    "plotData = batch\n",
    "plotData = plotData.reshape(28, 28)\n",
    "plt.imshow(plotData, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [빌드단계] Step 2) 모델 생성을 위한 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터가 들어갈 플레이스 홀더 선언\n",
    "X = tf.placeholder(tf.float32, [None, inputDataSize])\n",
    "# 학습데이터가 들어갈 플레이스 홀더 선언\n",
    "Y = tf.placeholder(tf.float32, [None, outputDataSize])\n",
    "\n",
    "# 임의의 난수를 선언하여 W,b 변수의 초기값을 선언 및 Neural Network Layer 구성\n",
    "if randomVariableType == 1:\n",
    "    # 1 : random_normal\n",
    "    # Input Layer\n",
    "    W_input = tf.Variable(tf.random_normal([inputDataSize, hiddenLayer1Size]),\n",
    "                          name = 'Weight_input')\n",
    "    b_input = tf.Variable(tf.random_normal([hiddenLayer1Size]), name = 'bias_input')\n",
    "\n",
    "    # Hidden Layer\n",
    "    # Layer1\n",
    "    W_hidden1 = tf.Variable(tf.random_normal([hiddenLayer1Size, hiddenLayer2Size]),\n",
    "                            name = 'Weight_hidden1')\n",
    "    b_hidden1 = tf.Variable(tf.random_normal([hiddenLayer2Size]),\n",
    "                            name = 'bias_hidden1')\n",
    "\n",
    "    # Layer2\n",
    "    W_hidden2 = tf.Variable(tf.random_normal([hiddenLayer2Size, hiddenLayer3Size]),\n",
    "                            name = 'Weight_hidden2')\n",
    "    b_hidden2 = tf.Variable(tf.random_normal([hiddenLayer3Size]),\n",
    "                            name = 'bias_hidden2')\n",
    "\n",
    "    # Layer3\n",
    "    W_hidden3 = tf.Variable(tf.random_normal([hiddenLayer3Size, outputLayerSize]),\n",
    "                            name = 'Weight_hidden3')\n",
    "    b_hidden3 = tf.Variable(tf.random_normal([outputLayerSize]),\n",
    "                            name = 'bias_hidden3')\n",
    "\n",
    "    # Output Layer\n",
    "    W_output = tf.Variable(tf.random_normal([outputLayerSize,outputDataSize]),\n",
    "                           name = 'Weight_output')\n",
    "    b_output = tf.Variable(tf.random_normal([outputDataSize]),\n",
    "                           name = 'bias_output')\n",
    "\n",
    "elif randomVariableType == 2:\n",
    "    # 2 : truncated_normal\n",
    "\n",
    "    # Input Layer\n",
    "    W_input = tf.Variable(tf.truncated_normal([inputDataSize, hiddenLayer1Size]),\n",
    "                          name = 'Weight_input')\n",
    "    b_input = tf.Variable(tf.truncated_normal([hiddenLayer1Size]),\n",
    "                          name = 'bias_input')\n",
    "\n",
    "    # Hidden Layer\n",
    "    # Layer1\n",
    "    W_hidden1 = tf.Variable(tf.truncated_normal([hiddenLayer1Size, hiddenLayer2Size]),\n",
    "                            name = 'Weight_hidden1')\n",
    "    b_hidden1 = tf.Variable(tf.truncated_normal([hiddenLayer2Size]), name = 'bias_hidden1')\n",
    "\n",
    "    # Layer2\n",
    "    W_hidden2 = tf.Variable(tf.truncated_normal([hiddenLayer2Size, hiddenLayer3Size]),\n",
    "                            name = 'Weight_hidden2')\n",
    "    b_hidden2 = tf.Variable(tf.truncated_normal([hiddenLayer3Size]),\n",
    "                            name = 'bias_hidden2')\n",
    "\n",
    "    # Layer3\n",
    "    W_hidden3 = tf.Variable(tf.truncated_normal([hiddenLayer3Size, outputLayerSize]),\n",
    "                            name = 'Weight_hidden3')\n",
    "    b_hidden3 = tf.Variable(tf.truncated_normal([outputLayerSize]),\n",
    "                            name = 'bias_hidden3')\n",
    "\n",
    "    # Output Layer\n",
    "    W_output = tf.Variable(tf.truncated_normal([outputLayerSize, outputDataSize]),\n",
    "                           name = 'Weight_output')\n",
    "    b_output = tf.Variable(tf.truncated_normal([outputDataSize]),\n",
    "                           name = 'bias_output')\n",
    "\n",
    "elif randomVariableType == 3:\n",
    "    # 3 : random_uniform\n",
    "    # Input Layer\n",
    "    W_input = tf.Variable(tf.random_uniform([inputDataSize, hiddenLayer1Size]),\n",
    "                          name = 'Weight_input')\n",
    "    b_input = tf.Variable(tf.random_uniform([hiddenLayer1Size]),\n",
    "                          name = 'bias_input')\n",
    "\n",
    "    # Hidden Layer\n",
    "    # Layer1\n",
    "    W_hidden1 = tf.Variable(tf.random_uniform([hiddenLayer1Size, hiddenLayer2Size]),\n",
    "                            name = 'Weight_hidden1')\n",
    "    b_hidden1 = tf.Variable(tf.random_uniform([hiddenLayer2Size]),\n",
    "                            name = 'bias_hidden1')\n",
    "\n",
    "    # Layer2\n",
    "    W_hidden2 = tf.Variable(tf.random_uniform([hiddenLayer2Size, hiddenLayer3Size]),\n",
    "                            name = 'Weight_hidden2')\n",
    "    b_hidden2 = tf.Variable(tf.random_uniform([hiddenLayer3Size]),\n",
    "                            name = 'bias_hidden2')\n",
    "\n",
    "    # Layer3\n",
    "    W_hidden3 = tf.Variable(tf.random_uniform([hiddenLayer3Size, outputLayerSize]),\n",
    "                            name = 'Weight_hidden3')\n",
    "    b_hidden3 = tf.Variable(tf.random_uniform([outputLayerSize]),\n",
    "                            name = 'bias_hidden3')\n",
    "\n",
    "    # Output Layer\n",
    "    W_output = tf.Variable(tf.random_uniform([outputLayerSize, outputDataSize]),\n",
    "                           name = 'Weight_output')\n",
    "    b_output = tf.Variable(tf.random_uniform([outputDataSize]),\n",
    "                           name = 'bias_output')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [빌드단계] 3) 학습 모델 그래프 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-d2f65710a8a6>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3-1) 학습데이터를 대표 하는 가설 그래프 선언\n",
    "# hypothesis - Input Layer\n",
    "Layer_input_hypothesis = tf.nn.relu(tf.matmul(X, W_input)+b_input)\n",
    "# hypothesis - Hidden Layer\n",
    "Layer_hidden1_hypothesis = tf.nn.relu(tf.matmul(Layer_input_hypothesis,W_hidden1)+b_hidden1)\n",
    "Layer_hidden2_hypothesis = tf.nn.relu(tf.matmul(Layer_hidden1_hypothesis,W_hidden2)+b_hidden2)\n",
    "Layer_hidden3_hypothesis = tf.nn.relu(tf.matmul(Layer_hidden2_hypothesis,W_hidden3)+b_hidden3)\n",
    "# hypothesis - Output Layer\n",
    "Layer_output_hypothesis_logit = tf.matmul(Layer_hidden3_hypothesis, W_output)+b_output\n",
    "\n",
    "# 3-2) 비용함수(오차함수,손실함수) 선언\n",
    "costFunction = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Layer_output_hypothesis_logit, labels=Y))\n",
    "\n",
    "# 3-3) 비용함수의 값이 최소가 되도록 하는 최적화함수 선언\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learningRate)\n",
    "train = optimizer.minimize(costFunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실행단계] 학습 모델 그래프를 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Train(Optimization) Start \n",
      "(60000, 28, 28)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (60000, 28, 28) for Tensor 'Placeholder:0', which has shape '(?, 784)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-791e93a774e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         cost_val, acc_val, _ = sess.run([costFunction, accuracy, train],\n\u001b[1;32m---> 29\u001b[1;33m                                 feed_dict = {X : batchX, Y:batchY})\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0maverage_costFunction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost_val\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotalBatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 960\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    961\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1157\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1160\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (60000, 28, 28) for Tensor 'Placeholder:0', which has shape '(?, 784)'"
     ]
    }
   ],
   "source": [
    "# 실행을 위한 세션 선언\n",
    "sess = tf.Session()\n",
    "# 최적화 과정을 통하여 구해질 변수 W,b 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 예측값, 정확도 수식 선언\n",
    "predicted = tf.equal(tf.argmax(Layer_output_hypothesis_logit, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted, tf.float32))\n",
    "\n",
    "# 학습 정확도를 저장할 리스트 선언\n",
    "train_accuracy = list()\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(\"Train(Optimization) Start \")\n",
    "batchX=train\n",
    "batchY=test\n",
    "for epoch in range(totalEpochs):\n",
    "    average_costFunction = 0\n",
    "    # 전체 batch 사이즈 구하기 (55000 / 200 = 275)\n",
    "    totalBatch = int(train.size / batch_size)\n",
    "\n",
    "    for step in range(totalBatch):\n",
    "        #batchX, batchY = train.next_batch(batch_size)\n",
    "        for j in range(batch_size):\n",
    "                   batchX[j]=train[step*batch_size+j]\n",
    "                   batchY[j]=test[step*batch_size+j]\n",
    "        print(train.shape)            \n",
    "        cost_val, acc_val, _ = sess.run([costFunction, accuracy, train],\n",
    "                                feed_dict = {X : batchX, Y:batchY})\n",
    "        train_accuracy.append(acc_val)\n",
    "        average_costFunction = cost_val / totalBatch\n",
    "\n",
    "    print(\"epoch : {}, cost = {}\".format(epoch,average_costFunction))\n",
    "\n",
    "\n",
    "# 정확도 결과 확인 그래프\n",
    "plt.plot(range(len(train_accuracy)), train_accuracy, linewidth = 2, label = 'Training')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Result\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Train Finished\")\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(\"[Test Result]\")\n",
    "# 최적화가 끝난 학습 모델 테스트\n",
    "h_val, p_val, a_val = sess.run([Layer_output_hypothesis_logit, predicted, accuracy],\n",
    "                        feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n",
    "print(\"\\nHypothesis : {} \\nPrediction : {} \\nAccuracy : {}\".format(h_val,p_val,a_val))\n",
    "\n",
    "\n",
    "# matplotlib 를 이용하여 학습 결과를 시각화\n",
    "# 라벨 0 / 4 는 앞자리는 예측값 / 실제값 을 나타냄\n",
    "\n",
    "fig = plt.figure(figsize=(8,15))\n",
    "for i in range(10):\n",
    "    c = 1\n",
    "    for (image, label, h) in zip(mnist.test.images, mnist.test.labels, h_val):\n",
    "        prediction, actual = np.argmax(h), np.argmax(label)\n",
    "        if prediction != i:\n",
    "            continue\n",
    "        if (c < 4 and i == actual) or (c >= 4 and i != actual):\n",
    "            subplot = fig.add_subplot(10,6,i*6+c)\n",
    "            subplot.set_xticks([])\n",
    "            subplot.set_yticks([])\n",
    "            subplot.set_title('%d / %d' % (prediction, actual))\n",
    "            subplot.imshow(image.reshape((28,28)), vmin=0, vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "            c += 1\n",
    "            if c > 6:\n",
    "                break\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "#세션종료\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
